# churn-waze-prediction

Absolument ! Je vais t'aider Ã  rÃ©diger ce rapport de maniÃ¨re claire, concise et professionnelle pour ton portfolio GitHub. Je vais structurer le contenu pour qu'il soit facile Ã  lire et Ã  comprendre, tout en mettant en valeur les Ã©tapes clÃ©s de ton projet.

### Projet : PrÃ©diction du Churn Utilisateur pour Waze

Ce projet vise Ã  crÃ©er un modÃ¨le de machine learning capable de prÃ©dire les utilisateurs qui risquent de cesser d'utiliser l'application Waze (churn). L'objectif est de permettre Ã  l'entreprise de mettre en place des stratÃ©gies de rÃ©tention ciblÃ©es pour fidÃ©liser ses utilisateurs.

---

### 1. PrÃ©paration et Traitement des DonnÃ©es

* **Analyse Exploratoire des DonnÃ©es (AED)** : Une analyse des donnÃ©es a Ã©tÃ© rÃ©alisÃ©e pour comprendre les caractÃ©ristiques des utilisateurs.
* **CrÃ©ation de CaractÃ©ristiques (Feature Engineering)** : De nouvelles variables ont Ã©tÃ© crÃ©Ã©es pour enrichir le modÃ¨le, telles que le pourcentage de sessions sur le dernier mois, l'indication d'un conducteur professionnel, la moyenne de sessions par jour, etc.
* **Encodage des Variables CatÃ©gorielles** : Les variables non numÃ©riques (`label` et `device`) ont Ã©tÃ© transformÃ©es en formats comprÃ©hensibles pour le modÃ¨le.
* **Division du Dataset** : Le jeu de donnÃ©es a Ã©tÃ© scindÃ© en trois parties pour l'entraÃ®nement (60%), la validation (20%) et le test (20%).

---

### 2. ModÃ¨les Ã‰valuÃ©s

Deux modÃ¨les basÃ©s sur les arbres de dÃ©cision ont Ã©tÃ© choisis pour leur capacitÃ© Ã  gÃ©rer des donnÃ©es complexes et des interactions non linÃ©aires :
* **Random Forest**
* **XGBoost**

---

### 3. Ajustement du Seuil de Classification

Un ajustement du seuil de classification a Ã©tÃ© rÃ©alisÃ© pour amÃ©liorer les performances du modÃ¨le. Initialement, les modÃ¨les utilisent un seuil par dÃ©faut de **0.5**. Pour maximiser le compromis entre la **prÃ©cision** et le **rappel**, un seuil optimal a Ã©tÃ© recherchÃ© sur l'ensemble de validation en maximisant le **F1-score**.

---

### 4. RÃ©sultats et Analyse

Les modÃ¨les ont Ã©tÃ© Ã©valuÃ©s sur l'ensemble de test, en utilisant d'abord le seuil par dÃ©faut (0.5), puis le seuil optimisÃ©.

#### RÃ©sultats avec Seuil par DÃ©faut (0.5)

| ModÃ¨le | PrÃ©cision | Rappel | F1-score | Accuracy | ROC AUC |
| :--- | :--- | :--- | :--- | :--- | :--- |
| **Random Forest** | 0.314 | 0.650 | 0.424 | 0.686 | 0.735 |
| **XGBoost** | 0.303 | 0.713 | 0.425 | 0.658 | 0.733 |

#### RÃ©sultats aprÃ¨s Optimisation du Seuil

| ModÃ¨le | Seuil Optimal | PrÃ©cision | Rappel | F1-score | Accuracy | ROC AUC |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| **Random Forest** | 0.524 | 0.330 | 0.603 | 0.427 | 0.713 | 0.735 |
| **XGBoost** | 0.508 | 0.311 | 0.689 | 0.429 | 0.674 | 0.733 |

#### Analyse Comparative

L'ajustement du seuil a permis d'amÃ©liorer la prÃ©cision et l'accuracy des deux modÃ¨les. En se concentrant sur le F1-score, qui est une mesure d'Ã©quilibre entre la prÃ©cision et le rappel, on observe une lÃ©gÃ¨re amÃ©lioration pour les deux modÃ¨les.

* **Random Forest** : L'optimisation du seuil a lÃ©gÃ¨rement amÃ©liorÃ© la prÃ©cision et l'accuracy, avec une lÃ©gÃ¨re baisse du rappel. Le F1-score reste stable.
* **XGBoost** : L'optimisation a permis d'amÃ©liorer la prÃ©cision, le F1-score et l'accuracy, avec une lÃ©gÃ¨re baisse du rappel.

---

### 5. Conclusion et Perspectives

L'objectif principal Ã©tait de trouver le meilleur compromis entre la prÃ©cision (limiter les faux positifs) et le rappel (dÃ©tecter un maximum de churners potentiels).

Le choix du modÃ¨le dÃ©pendra de l'objectif mÃ©tier :
* Si l'entreprise souhaite **maximiser le rappel** pour ne manquer aucun utilisateur Ã  risque (mÃªme si cela gÃ©nÃ¨re plus de faux positifs), un seuil plus bas pourrait Ãªtre utilisÃ©.
* Si elle prÃ©fÃ¨re **limiter les faux positifs** pour ne pas dÃ©penser de ressources inutilement, un seuil lÃ©gÃ¨rement plus Ã©levÃ© (proche de l'optimal) est plus appropriÃ©.

En ajustant le seuil, nous avons un levier puissant pour adapter le modÃ¨le aux prioritÃ©s de l'entreprise, sans avoir Ã  modifier le modÃ¨le en profondeur.

Pour amÃ©liorer ce projet, il serait intÃ©ressant de :
* Tester des techniques d'optimisation du seuil plus avancÃ©es, en tenant compte des coÃ»ts mÃ©tier.
* Ã‰valuer d'autres modÃ¨les ou des techniques d'**ensemble learning**.
* DÃ©velopper une interface pour le suivi en continu des performances en production.

---

### 6. Code et Ressources

Le code source complet de ce projet, y compris l'implÃ©mentation de l'ajustement du seuil et les visualisations associÃ©es (courbes ROC et Precision-Recall), est disponible sur ce dÃ©pÃ´t GitHub.

J'espÃ¨re que cette version te plaÃ®t ! Elle est prÃªte Ã  Ãªtre dÃ©posÃ©e sur ton portfolio. ğŸ˜Š


# ğŸ›°ï¸ PrÃ©diction du Churn Utilisateur â€“ Waze

Ce projet a pour objectif de dÃ©velopper un modÃ¨le de machine learning capable de prÃ©dire quels utilisateurs risquent de **cesser dâ€™utiliser lâ€™application Waze**. Une telle prÃ©diction permettrait Ã  lâ€™entreprise de cibler efficacement ses actions de **fidÃ©lisation**.

---

## ğŸ” 1. PrÃ©paration et Traitement des DonnÃ©es

- **Analyse exploratoire** : Ã‰tude des comportements utilisateurs.
- **Feature engineering** :
  - % de sessions sur le dernier mois
  - Indication conducteur professionnel
  - Sessions moyennes par jour, etc.
- **Encodage des variables catÃ©gorielles** : `label`, `device` â†’ variables numÃ©riques.
- **Split des donnÃ©es** :
  - **EntraÃ®nement** : 60%
  - **Validation** : 20%
  - **Test** : 20%

---

## ğŸŒ² 2. ModÃ¨les Ã‰valuÃ©s

Deux modÃ¨les basÃ©s sur les **arbres de dÃ©cision** ont Ã©tÃ© comparÃ©s :

- `Random Forest`
- `XGBoost`

Ces modÃ¨les sont performants pour gÃ©rer des interactions complexes et des donnÃ©es non linÃ©aires.

---

## âš™ï¸ 3. Ajustement du Seuil de Classification

Par dÃ©faut, les modÃ¨les utilisent un seuil de 0.5.  
Un **ajustement du seuil** a Ã©tÃ© rÃ©alisÃ© pour maximiser le **F1-score** sur lâ€™ensemble de validation, et donc amÃ©liorer le compromis **prÃ©cision / rappel**.

---

## ğŸ“Š 4. RÃ©sultats

### âœ… Seuil par DÃ©faut (0.5)

| ModÃ¨le         | PrÃ©cision | Rappel | F1-score | Accuracy | ROC AUC |
|----------------|-----------|--------|----------|----------|---------|
| Random Forest  | 0.314     | 0.650  | 0.424    | 0.686    | 0.735   |
| XGBoost        | 0.303     | 0.713  | 0.425    | 0.658    | 0.733   |

### ğŸ¯ Seuil OptimisÃ©

| ModÃ¨le         | Seuil     | PrÃ©cision | Rappel | F1-score | Accuracy | ROC AUC |
|----------------|-----------|-----------|--------|----------|----------|---------|
| Random Forest  | 0.524     | 0.330     | 0.603  | 0.427    | 0.713    | 0.735   |
| XGBoost        | 0.508     | 0.311     | 0.689  | 0.429    | 0.674    | 0.733   |

### ğŸ“Œ Analyse Comparative

- **Random Forest** :
  - + PrÃ©cision, + Accuracy, F1-score stable
  - LÃ©gÃ¨re baisse du rappel
- **XGBoost** :
  - + PrÃ©cision, + F1-score, + Accuracy
  - Baisse modÃ©rÃ©e du rappel

---

## ğŸ§  5. Conclusion & Perspectives

Le **choix du seuil** dÃ©pend des objectifs mÃ©tiers :

- ğŸ¯ **Maximiser le rappel** : mieux identifier tous les churners (mÃªme avec des faux positifs).
- ğŸ’° **Maximiser la prÃ©cision** : Ã©viter dâ€™agir inutilement sur des utilisateurs fidÃ¨les.

Ajuster le seuil est un **levier stratÃ©gique** : il permet dâ€™adapter le modÃ¨le aux besoins sans le modifier.

### ğŸ”„ AmÃ©liorations possibles

- Optimisation du seuil selon des **coÃ»ts mÃ©tier**
- Tester dâ€™autres modÃ¨les / techniques dâ€™**ensemble learning**
- CrÃ©er une **interface de monitoring** pour la mise en production

---

## ğŸ’» 6. Code & Ressources

Le code source du projet est disponible dans ce dÃ©pÃ´t :
- PrÃ©paration des donnÃ©es
- EntraÃ®nement des modÃ¨les
- Optimisation du seuil
- Visualisations ROC et Precision-Recall

> ğŸ‘‰ *N'hÃ©site pas Ã  explorer le code et Ã  proposer des amÃ©liorations via issues ou pull requests !*

---


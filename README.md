# churn-waze-prediction-
# ğŸ›°ï¸ PrÃ©diction du Churn Utilisateur â€“ Waze

Ce projet a pour objectif de dÃ©velopper un modÃ¨le de machine learning capable de prÃ©dire quels utilisateurs risquent de **cesser dâ€™utiliser lâ€™application Waze**. Une telle prÃ©diction permettrait Ã  lâ€™entreprise de cibler efficacement ses actions de **fidÃ©lisation**.

---

## ğŸ” 1. PrÃ©paration et Traitement des DonnÃ©es

- **Analyse exploratoire** : Ã‰tude des comportements utilisateurs.
- **Feature engineering** :
  - % de sessions sur le dernier mois
  - Indication conducteur professionnel
  - Sessions moyennes par jour, etc.
- **Encodage des variables catÃ©gorielles** : `label`, `device` â†’ variables numÃ©riques.
- **Split des donnÃ©es** :
  - **EntraÃ®nement** : 60%
  - **Validation** : 20%
  - **Test** : 20%

---

## ğŸŒ² 2. ModÃ¨les Ã‰valuÃ©s

Deux modÃ¨les basÃ©s sur les **arbres de dÃ©cision** ont Ã©tÃ© comparÃ©s :

- `Random Forest`
- `XGBoost`

Ces modÃ¨les sont performants pour gÃ©rer des interactions complexes et des donnÃ©es non linÃ©aires.

---

## âš™ï¸ 3. Ajustement du Seuil de Classification

Par dÃ©faut, les modÃ¨les utilisent un seuil de 0.5.  
Un **ajustement du seuil** a Ã©tÃ© rÃ©alisÃ© pour maximiser le **F1-score** sur lâ€™ensemble de validation, et donc amÃ©liorer le compromis **prÃ©cision / rappel**.

---

## ğŸ“Š 4. RÃ©sultats

### âœ… Seuil par DÃ©faut (0.5)

| ModÃ¨le         | PrÃ©cision | Rappel | F1-score | Accuracy | ROC AUC |
|----------------|-----------|--------|----------|----------|---------|
| Random Forest  | 0.314     | 0.650  | 0.424    | 0.686    | 0.735   |
| XGBoost        | 0.303     | 0.713  | 0.425    | 0.658    | 0.733   |

### ğŸ¯ Seuil OptimisÃ©

| ModÃ¨le         | Seuil     | PrÃ©cision | Rappel | F1-score | Accuracy | ROC AUC |
|----------------|-----------|-----------|--------|----------|----------|---------|
| Random Forest  | 0.524     | 0.330     | 0.603  | 0.427    | 0.713    | 0.735   |
| XGBoost        | 0.508     | 0.311     | 0.689  | 0.429    | 0.674    | 0.733   |

### ğŸ“Œ Analyse Comparative

- **Random Forest** :
  - + PrÃ©cision, + Accuracy, F1-score stable
  - LÃ©gÃ¨re baisse du rappel
- **XGBoost** :
  - + PrÃ©cision, + F1-score, + Accuracy
  - Baisse modÃ©rÃ©e du rappel

---

## ğŸ§  5. Conclusion & Perspectives

Le **choix du seuil** dÃ©pend des objectifs mÃ©tiers :

- ğŸ¯ **Maximiser le rappel** : mieux identifier tous les churners (mÃªme avec des faux positifs).
- ğŸ’° **Maximiser la prÃ©cision** : Ã©viter dâ€™agir inutilement sur des utilisateurs fidÃ¨les.

Ajuster le seuil est un **levier stratÃ©gique** : il permet dâ€™adapter le modÃ¨le aux besoins sans le modifier.

### ğŸ”„ AmÃ©liorations possibles

- Optimisation du seuil selon des **coÃ»ts mÃ©tier**
- Tester dâ€™autres modÃ¨les / techniques dâ€™**ensemble learning**
- CrÃ©er une **interface de monitoring** pour la mise en production

---

## ğŸ’» 6. Code & Ressources

Le code source du projet est disponible dans ce dÃ©pÃ´t :
- PrÃ©paration des donnÃ©es
- EntraÃ®nement des modÃ¨les
- Optimisation du seuil
- Visualisations ROC et Precision-Recall

> ğŸ‘‰ *N'hÃ©site pas Ã  explorer le code et Ã  proposer des amÃ©liorations via issues ou pull requests !*

---


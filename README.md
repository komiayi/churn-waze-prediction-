# churn-waze-prediction
Ce projet vise Ã  crÃ©er un modÃ¨le de machine learning capable de prÃ©dire les utilisateurs qui risquent de cesser d'utiliser l'application Waze (churn). L'objectif est de permettre Ã  l'entreprise de mettre en place des stratÃ©gies de rÃ©tention ciblÃ©es pour fidÃ©liser ses utilisateurs.

---

### ğŸ” 1. PrÃ©paration et Traitement des DonnÃ©es

* **Analyse Exploratoire des DonnÃ©es** : Une analyse des donnÃ©es a Ã©tÃ© rÃ©alisÃ©e pour comprendre les caractÃ©ristiques des utilisateurs.
* **CrÃ©ation de CaractÃ©ristiques** : De nouvelles variables ont Ã©tÃ© crÃ©Ã©es pour enrichir le modÃ¨le, telles que le pourcentage de sessions sur le dernier mois, l'indication d'un conducteur professionnel, la moyenne de sessions par jour, etc.
* **Encodage des Variables CatÃ©gorielles** : Les variables non numÃ©riques (`label` et `device`) ont Ã©tÃ© transformÃ©es en formats comprÃ©hensibles pour le modÃ¨le.
* **Division du Dataset** : Le jeu de donnÃ©es a Ã©tÃ© scindÃ© en trois parties pour l'entraÃ®nement (60%), la validation (20%) et le test (20%).

---

### ğŸŒ² 2. ModÃ¨les Ã‰valuÃ©s

Deux modÃ¨les basÃ©s sur les arbres de dÃ©cision ont Ã©tÃ© choisis pour leur capacitÃ© Ã  gÃ©rer des donnÃ©es complexes et des interactions non linÃ©aires :
* **Random Forest**
* **XGBoost**

---

### âš™ï¸ 3. Ajustement du Seuil de Classification

Un ajustement du seuil de classification a Ã©tÃ© rÃ©alisÃ© pour amÃ©liorer les performances du modÃ¨le. Initialement, les modÃ¨les utilisent un seuil par dÃ©faut de **0.5**. Pour maximiser le compromis entre la **prÃ©cision** et le **rappel**, un seuil optimal a Ã©tÃ© recherchÃ© sur l'ensemble de validation en maximisant le **F1-score**.

---

### ğŸ“Š 4. RÃ©sultats et Analyse

Les modÃ¨les ont Ã©tÃ© Ã©valuÃ©s sur l'ensemble de test, en utilisant d'abord le seuil par dÃ©faut (0.5), puis le seuil optimisÃ©.

#### âœ… Seuil par dÃ©faut (0.5)

| ModÃ¨le | PrÃ©cision | Rappel | F1-score | Accuracy | ROC AUC |
| :--- | :--- | :--- | :--- | :--- | :--- |
| **Random Forest** | 0.314 | 0.650 | 0.424 | 0.686 | 0.735 |
| **XGBoost** | 0.303 | 0.713 | 0.425 | 0.658 | 0.733 |

#### ğŸ¯ AprÃ¨s optimisation du Seuil

| ModÃ¨le | Seuil Optimal | PrÃ©cision | Rappel | F1-score | Accuracy | ROC AUC |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| **Random Forest** | 0.524 | 0.330 | 0.603 | 0.427 | 0.713 | 0.735 |
| **XGBoost** | 0.508 | 0.311 | 0.689 | 0.429 | 0.674 | 0.733 |

#### Analyse Comparative

L'ajustement du seuil a permis d'amÃ©liorer la prÃ©cision et l'accuracy des deux modÃ¨les. En se concentrant sur le F1-score, qui est une mesure d'Ã©quilibre entre la prÃ©cision et le rappel, on observe une lÃ©gÃ¨re amÃ©lioration pour les deux modÃ¨les.

* **Random Forest** : L'optimisation du seuil a lÃ©gÃ¨rement amÃ©liorÃ© la prÃ©cision et l'accuracy, avec une lÃ©gÃ¨re baisse du rappel. Le F1-score reste stable.
* **XGBoost** : L'optimisation a permis d'amÃ©liorer la prÃ©cision, le F1-score et l'accuracy, avec une lÃ©gÃ¨re baisse du rappel.

---

### 5. Conclusion et Perspectives

L'objectif principal Ã©tait de trouver le meilleur compromis entre la prÃ©cision (limiter les faux positifs) et le rappel (dÃ©tecter un maximum de churners potentiels).

Le choix du modÃ¨le dÃ©pendra de l'objectif mÃ©tier :
* Si l'entreprise souhaite **maximiser le rappel** pour ne manquer aucun utilisateur Ã  risque (mÃªme si cela gÃ©nÃ¨re plus de faux positifs), un seuil plus bas pourrait Ãªtre utilisÃ©.
* Si elle prÃ©fÃ¨re **limiter les faux positifs** pour ne pas dÃ©penser de ressources inutilement, un seuil lÃ©gÃ¨rement plus Ã©levÃ© (proche de l'optimal) est plus appropriÃ©.

En ajustant le seuil, nous avons un levier puissant pour adapter le modÃ¨le aux prioritÃ©s de l'entreprise, sans avoir Ã  modifier le modÃ¨le en profondeur.

Pour amÃ©liorer ce projet, il serait intÃ©ressant de :
* Tester des techniques d'optimisation du seuil plus avancÃ©es, en tenant compte des coÃ»ts mÃ©tier.
* Ã‰valuer d'autres modÃ¨les ou des techniques d'**ensemble learning**.
* DÃ©velopper une interface pour le suivi en continu des performances en production.

---

### 6. Code et Ressources

Le code source complet de ce projet, y compris l'implÃ©mentation de l'ajustement du seuil et les visualisations associÃ©es (courbes ROC et Precision-Recall), est disponible sur ce dÃ©pÃ´t GitHub.

J'espÃ¨re que cette version te plaÃ®t ! Elle est prÃªte Ã  Ãªtre dÃ©posÃ©e sur ton portfolio. ğŸ˜Š


# ğŸ›°ï¸ PrÃ©diction du Churn Utilisateur â€“ Waze

Ce projet prÃ©sente une analyse complÃ¨te visant Ã  prÃ©dire les utilisateurs susceptibles de cesser dâ€™utiliser **Waze** (churn).  
Lâ€™objectif est de dÃ©velopper un modÃ¨le prÃ©dictif pour anticiper les dÃ©parts et proposer des stratÃ©gies de rÃ©tention.

ğŸ“ Tout le projet est contenu dans un seul notebook Jupyter :  
ğŸ‘‰ [`churn_prediction_waze.ipynb`](./churn_prediction_waze.ipynb)

---

## ğŸ” Objectifs

- Identifier les churners via des donnÃ©es dâ€™usage anonymisÃ©es
- Comparer des modÃ¨les de machine learning
- Ajuster dynamiquement le **seuil de classification** pour maximiser le **F1-score**
- Proposer des recommandations mÃ©tier Ã  partir des rÃ©sultats

---

## ğŸ“Œ MÃ©thodologie dans le notebook

âœ”ï¸ **PrÃ©traitement des donnÃ©es**
- Nettoyage
- Feature engineering (sessions rÃ©centes, utilisateur pro, etc.)
- Encodage des variables catÃ©gorielles

âœ”ï¸ **ModÃ©lisation**
- ModÃ¨les testÃ©s : Random Forest, XGBoost
- SÃ©paration : train (60%), validation (20%), test (20%)

âœ”ï¸ **Optimisation du seuil**
- Maximisation du F1-score via une recherche de seuil optimal
- Analyse d'impact mÃ©tier : rappel vs. prÃ©cision

âœ”ï¸ **Visualisations**
- Courbes ROC, courbes PrÃ©cision-Rappel, F1/Seuil

ğŸ“Š Voir les rÃ©sultats dans le dossier [`/figures`](./figures)

---

## ğŸ§  RÃ©sultats clÃ©s

| ModÃ¨le         | Seuil     | PrÃ©cision | Rappel | F1-score | Accuracy |
|----------------|-----------|-----------|--------|----------|----------|
| Random Forest  | 0.524     | 0.330     | 0.603  | 0.427    | 0.713    |
| XGBoost        | 0.508     | 0.311     | 0.689  | 0.429    | 0.674    |

---

## ğŸ§  Conclusion

- Lâ€™ajustement du **seuil** amÃ©liore le compromis entre **faux positifs et faux nÃ©gatifs**
- Le **choix mÃ©tier** guide lâ€™interprÃ©tation : faut-il dÃ©tecter tous les churners ou Ã©viter dâ€™alerter inutilement ?

### ğŸ”„ Perspectives

- Ajouter les coÃ»ts mÃ©tier dans lâ€™optimisation
- Tester dâ€™autres modÃ¨les avancÃ©s
- DÃ©ployer un tableau de bord de monitoring

---

## ğŸš€ Reproduire le projet

### 1. Cloner le dÃ©pÃ´t

```bash
git clone https://github.com/komiayi/churn-waze-prediction-.git
cd churn-waze-prediction-


